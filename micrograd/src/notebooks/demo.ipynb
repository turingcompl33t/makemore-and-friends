{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a461ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd.engine import Value\n",
    "from micrograd.nn import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361118e",
   "metadata": {},
   "source": [
    "**Build a Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f634a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=128, noise=0.1)\n",
    "# make y be -1 or 1\n",
    "y = y*2 - 1 \n",
    "\n",
    "# visualize in 2D\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=20, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c305d6",
   "metadata": {},
   "source": [
    "**Define a Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model \n",
    "model = MLP(2, [16, 16, 1])\n",
    "print(f\"number of parameters = {len(model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff079d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "def loss(batch_size: int | None = None) -> tuple[Value, float]:\n",
    "    # inline DataLoader\n",
    "    if batch_size is None:\n",
    "        Xb, yb = X, y\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X[ri], y[ri]\n",
    "    inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    \n",
    "    # SVM \"max-margin\" loss (tanh instead of relu)\n",
    "    losses = [(1 + -yi*scorei).tanh() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    \n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    \n",
    "    # total loss\n",
    "    total_loss = data_loss + reg_loss\n",
    "    assert isinstance(total_loss, Value)\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "total_loss, acc = loss()\n",
    "print(f\"total loss = {total_loss.data}, accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b034b",
   "metadata": {},
   "source": [
    "**Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18561b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 32\n",
    "\n",
    "# optimization\n",
    "for k in range(N_EPOCHS):\n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    \n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "    \n",
    "    # update (sgd) with learning rate decay\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "    \n",
    "    if k % 2 == 0:\n",
    "        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e20abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss, acc = loss()\n",
    "print(f\"loss {total_loss.data}, accuracy {acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abba9b",
   "metadata": {},
   "source": [
    "**Visualize Decision Boundary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf666ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.25\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
    "inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n",
    "scores = list(map(model, inputs))\n",
    "Z = np.array([s.data > 0 for s in scores])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
